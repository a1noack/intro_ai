{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as pp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([\n",
    "    [1,0,0,1,3,0,1,1,0,1],\n",
    "    [1,0,0,2,1,0,0,3,2,0],\n",
    "    [0,1,0,1,1,0,0,0,0,1],\n",
    "    [1,0,1,2,1,1,0,3,1,1],\n",
    "    [1,0,1,2,3,0,1,1,3,0],\n",
    "    [0,1,0,1,2,1,1,2,0,1],\n",
    "    [0,1,0,0,1,1,0,0,0,0],\n",
    "    [0,0,0,1,2,1,1,3,0,1],\n",
    "    [0,1,1,2,1,1,0,0,3,0],\n",
    "    [1,1,1,2,3,0,1,2,1,0],\n",
    "    [0,0,0,0,1,0,0,3,0,0],\n",
    "    [1,1,1,2,1,0,0,0,2,1]],\n",
    "    columns=['Alt','Bar','Fri','Pat','Price','Rain','Res','Type','Est','WillWait']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    return x*(1.-x)\n",
    "\n",
    "def sigmoid(x):\n",
    "#     return np.divide(1,np.add(1, np.exp(-x)))\n",
    "    return 1/(1+np.exp(-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN:\n",
    "    def __init__(self, data, lr):\n",
    "        self.lr = lr\n",
    "        self.X = data.values[:,:-1]\n",
    "        min_max_scaler = pp.MinMaxScaler(feature_range=(.1,.9))\n",
    "        self.X = min_max_scaler.fit_transform(self.X)\n",
    "        \n",
    "        self.Y = data.values[:,-1]\n",
    "\n",
    "        self.W1 = np.random.randn(9, 3)\n",
    "        self.b1 = 0\n",
    "        \n",
    "        self.W2 = np.random.randn(3, 1)\n",
    "        self.b2 = 0\n",
    "\n",
    "    def forward_pass(self):\n",
    "        self.o1 = np.dot(X, self.W1) #+ self.b1\n",
    "#         print(self.o1)\n",
    "        self.g1 = sigmoid(self.o1)\n",
    "        self.o2 = np.dot(self.g1, self.W2) #+ self.b2\n",
    "        self.Y_pred = sigmoid(self.o2)\n",
    "        return self.Y_pred\n",
    "\n",
    "    def loss(self):\n",
    "        diff = self.Y_pred - self.Y\n",
    "        diff_sq = np.square(diff)\n",
    "        self.se = np.sum(diff_sq)/2\n",
    "\n",
    "    def backpropagate(self):\n",
    "        self.Y_pred = np.reshape(self.Y_pred, (12,))\n",
    "        self.o_error = self.Y - self.Y_pred # error in output\n",
    "#         print(self.Y.shape, self.Y_pred.shape)\n",
    "#         print(self.o_error.shape)\n",
    "        self.o_delta = self.o_error*sigmoid_prime(self.Y_pred) # applying derivative of sigmoid to error\n",
    "        self.o_delta = np.reshape(self.o_delta, (12,1))\n",
    "#         print(self.o_delta.shape)\n",
    "        self.z2_error = np.dot(self.o_delta, self.W2.T) # z2 error: how much our hidden layer weights contributed to output error\n",
    "        self.z2_delta = self.z2_error*sigmoid_prime(self.g1) # applying derivative of sigmoid to z2 error\n",
    "        \n",
    "    def update(self):\n",
    "        self.W1 += self.lr*np.dot(self.X.T, self.z2_delta) # adjusting first set (input --> hidden) weights\n",
    "        self.W2 += self.lr*np.dot(self.g1.T, self.o_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamnoack/anaconda/envs/hack/lib/python3.5/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: \n",
      "0.274751321833\n",
      "Loss: \n",
      "0.492575158944\n",
      "Loss: \n",
      "0.489488118614\n",
      "Loss: \n",
      "0.266433155063\n",
      "Loss: \n",
      "0.255172554776\n",
      "Loss: \n",
      "0.434805840147\n",
      "Loss: \n",
      "0.250019724709\n",
      "Loss: \n",
      "0.250018506634\n",
      "Loss: \n",
      "0.250053026542\n",
      "Loss: \n",
      "0.250873567442\n",
      "Loss: \n",
      "0.291994361425\n",
      "Loss: \n",
      "0.250002803169\n",
      "Loss: \n",
      "0.250004787029\n",
      "Loss: \n",
      "0.250009601741\n",
      "Loss: \n",
      "0.250025484712\n",
      "Loss: \n",
      "0.250120132415\n",
      "Loss: \n",
      "0.252384444367\n",
      "Loss: \n",
      "0.270744599827\n",
      "Loss: \n",
      "0.270439684064\n",
      "Loss: \n",
      "0.270276030373\n",
      "Loss: \n",
      "0.270113302591\n",
      "Loss: \n",
      "0.2699540997\n",
      "Loss: \n",
      "0.269804350353\n",
      "Loss: \n",
      "0.269670422177\n",
      "Loss: \n",
      "0.26955734218\n",
      "Loss: \n",
      "0.269467643188\n",
      "Loss: \n",
      "0.269401113257\n",
      "Loss: \n",
      "0.269355388026\n",
      "Loss: \n",
      "0.269326943528\n",
      "Loss: \n",
      "0.269312010424\n",
      "Loss: \n",
      "0.269307163285\n",
      "Loss: \n",
      "0.269309579108\n",
      "Loss: \n",
      "0.269317072129\n",
      "Loss: \n",
      "0.269328017307\n",
      "Loss: \n",
      "0.269341238179\n",
      "Loss: \n",
      "0.269355897961\n",
      "Loss: \n",
      "0.269371408777\n",
      "Loss: \n",
      "0.269387361626\n",
      "Loss: \n",
      "0.269403474605\n",
      "Loss: \n",
      "0.269419555599\n",
      "Loss: \n",
      "0.269435475755\n",
      "Loss: \n",
      "0.269451150775\n",
      "Loss: \n",
      "0.269466527793\n",
      "Loss: \n",
      "0.269481576161\n",
      "Loss: \n",
      "0.269496281025\n",
      "Loss: \n",
      "0.269510638834\n",
      "Loss: \n",
      "0.269524654255\n",
      "Loss: \n",
      "0.269538338068\n",
      "Loss: \n",
      "0.269551705808\n",
      "Loss: \n",
      "0.269564776963\n",
      "Loss: \n",
      "0.269577574625\n",
      "Loss: \n",
      "0.26959012555\n",
      "Loss: \n",
      "0.26960246063\n",
      "Loss: \n",
      "0.269614615817\n",
      "Loss: \n",
      "0.269626633655\n",
      "Loss: \n",
      "0.269638565635\n",
      "Loss: \n",
      "0.269650475795\n",
      "Loss: \n",
      "0.269662446284\n",
      "Loss: \n",
      "0.269674586167\n",
      "Loss: \n",
      "0.269687045902\n",
      "Loss: \n",
      "0.269700042216\n",
      "Loss: \n",
      "0.269713903551\n",
      "Loss: \n",
      "0.269729159782\n",
      "Loss: \n",
      "0.269746739295\n",
      "Loss: \n",
      "0.26976847436\n",
      "Loss: \n",
      "0.26979875642\n",
      "Loss: \n",
      "0.269852869876\n",
      "Loss: \n",
      "0.270056632425\n",
      "Loss: \n",
      "0.278366009895\n",
      "Loss: \n",
      "0.27849588373\n",
      "Loss: \n",
      "0.289613538156\n",
      "Loss: \n",
      "0.269485928651\n",
      "Loss: \n",
      "0.309101264558\n",
      "Loss: \n",
      "0.250000004148\n",
      "Loss: \n",
      "0.250000004253\n",
      "Loss: \n",
      "0.250000004362\n",
      "Loss: \n",
      "0.250000004475\n",
      "Loss: \n",
      "0.250000004592\n",
      "Loss: \n",
      "0.250000004713\n",
      "Loss: \n",
      "0.250000004839\n",
      "Loss: \n",
      "0.25000000497\n",
      "Loss: \n",
      "0.250000005106\n",
      "Loss: \n",
      "0.250000005248\n",
      "Loss: \n",
      "0.250000005395\n",
      "Loss: \n",
      "0.250000005548\n",
      "Loss: \n",
      "0.250000005707\n",
      "Loss: \n",
      "0.250000005873\n",
      "Loss: \n",
      "0.250000006046\n",
      "Loss: \n",
      "0.250000006226\n",
      "Loss: \n",
      "0.250000006414\n",
      "Loss: \n",
      "0.250000006611\n",
      "Loss: \n",
      "0.250000006816\n",
      "Loss: \n",
      "0.25000000703\n",
      "Loss: \n",
      "0.250000007255\n",
      "Loss: \n",
      "0.250000007489\n",
      "Loss: \n",
      "0.250000007735\n",
      "Loss: \n",
      "0.250000007992\n",
      "Loss: \n",
      "0.250000008262\n",
      "Loss: \n",
      "0.250000008546\n",
      "Loss: \n",
      "0.250000008843\n",
      "Loss: \n",
      "0.250000009156\n",
      "Loss: \n",
      "0.250000009485\n",
      "Loss: \n",
      "0.250000009831\n",
      "Loss: \n",
      "0.250000010196\n",
      "Loss: \n",
      "0.250000010581\n",
      "Loss: \n",
      "0.250000010987\n",
      "Loss: \n",
      "0.250000011416\n",
      "Loss: \n",
      "0.25000001187\n",
      "Loss: \n",
      "0.250000012351\n",
      "Loss: \n",
      "0.25000001286\n",
      "Loss: \n",
      "0.2500000134\n",
      "Loss: \n",
      "0.250000013974\n",
      "Loss: \n",
      "0.250000014584\n",
      "Loss: \n",
      "0.250000015234\n",
      "Loss: \n",
      "0.250000015926\n",
      "Loss: \n",
      "0.250000016666\n",
      "Loss: \n",
      "0.250000017456\n",
      "Loss: \n",
      "0.250000018302\n",
      "Loss: \n",
      "0.25000001921\n",
      "Loss: \n",
      "0.250000020184\n",
      "Loss: \n",
      "0.250000021233\n",
      "Loss: \n",
      "0.250000022363\n",
      "Loss: \n",
      "0.250000023582\n",
      "Loss: \n",
      "0.250000024902\n",
      "Loss: \n",
      "0.250000026332\n",
      "Loss: \n",
      "0.250000027885\n",
      "Loss: \n",
      "0.250000029576\n",
      "Loss: \n",
      "0.250000031422\n",
      "Loss: \n",
      "0.250000033441\n",
      "Loss: \n",
      "0.250000035657\n",
      "Loss: \n",
      "0.250000038093\n",
      "Loss: \n",
      "0.250000040783\n",
      "Loss: \n",
      "0.250000043759\n",
      "Loss: \n",
      "0.250000047066\n",
      "Loss: \n",
      "0.250000050753\n",
      "Loss: \n",
      "0.250000054879\n",
      "Loss: \n",
      "0.250000059518\n",
      "Loss: \n",
      "0.250000064756\n",
      "Loss: \n",
      "0.2500000707\n",
      "Loss: \n",
      "0.250000077482\n",
      "Loss: \n",
      "0.250000085265\n",
      "Loss: \n",
      "0.250000094254\n",
      "Loss: \n",
      "0.250000104708\n",
      "Loss: \n",
      "0.250000116959\n",
      "Loss: \n",
      "0.250000131441\n",
      "Loss: \n",
      "0.25000014872\n",
      "Loss: \n",
      "0.250000169557\n",
      "Loss: \n",
      "0.250000194986\n",
      "Loss: \n",
      "0.250000226439\n",
      "Loss: \n",
      "0.25000026595\n",
      "Loss: \n",
      "0.250000316474\n",
      "Loss: \n",
      "0.250000382437\n",
      "Loss: \n",
      "0.250000470696\n",
      "Loss: \n",
      "0.250000592308\n",
      "Loss: \n",
      "0.250000765984\n",
      "Loss: \n",
      "0.250001025311\n",
      "Loss: \n",
      "0.250001435172\n",
      "Loss: \n",
      "0.250002133307\n",
      "Loss: \n",
      "0.250003451214\n",
      "Loss: \n",
      "0.250006339502\n",
      "Loss: \n",
      "0.250014341756\n",
      "Loss: \n",
      "0.250047923914\n",
      "Loss: \n",
      "0.250391583576\n",
      "Loss: \n",
      "0.266045352022\n",
      "Loss: \n",
      "0.269122504031\n",
      "Loss: \n",
      "0.269356537386\n",
      "Loss: \n",
      "0.269509098604\n",
      "Loss: \n",
      "0.269619283493\n",
      "Loss: \n",
      "0.269703873526\n",
      "Loss: \n",
      "0.269771536032\n",
      "Loss: \n",
      "0.26982728966\n",
      "Loss: \n",
      "0.269874278845\n",
      "Loss: \n",
      "0.269914591688\n",
      "Loss: \n",
      "0.269949678406\n",
      "Loss: \n",
      "0.269980582833\n",
      "Loss: \n",
      "0.270008078552\n",
      "Loss: \n",
      "0.270032752992\n",
      "Loss: \n",
      "0.270055061518\n",
      "Loss: \n",
      "0.270075363431\n",
      "Loss: \n",
      "0.270093946636\n",
      "Loss: \n",
      "0.270111044972\n",
      "Loss: \n",
      "0.270126850654\n",
      "Loss: \n",
      "0.270141523387\n",
      "Loss: \n",
      "0.270155197145\n",
      "Loss: \n",
      "0.27016798531\n",
      "Loss: \n",
      "0.2701799846\n",
      "Loss: \n",
      "0.270191278127\n",
      "Loss: \n",
      "0.270201937797\n",
      "Loss: \n",
      "0.270212026212\n",
      "Loss: \n",
      "0.270221598198\n",
      "Loss: \n",
      "0.270230702038\n",
      "Loss: \n",
      "0.270239380476\n",
      "Loss: \n",
      "0.270247671548\n",
      "Loss: \n",
      "0.270255609262\n",
      "Loss: \n",
      "0.27026322417\n",
      "Loss: \n",
      "0.270270543848\n",
      "Loss: \n",
      "0.2702775933\n",
      "Loss: \n",
      "0.2702843953\n",
      "Loss: \n",
      "0.270290970694\n",
      "Loss: \n",
      "0.270297338645\n",
      "Loss: \n",
      "0.270303516862\n",
      "Loss: \n",
      "0.270309521789\n",
      "Loss: \n",
      "0.270315368778\n",
      "Loss: \n",
      "0.270321072241\n",
      "Loss: \n",
      "0.270326645787\n",
      "Loss: \n",
      "0.270332102347\n",
      "Loss: \n",
      "0.270337454291\n",
      "Loss: \n",
      "0.270342713535\n",
      "Loss: \n",
      "0.270347891646\n",
      "Loss: \n",
      "0.270352999943\n",
      "Loss: \n",
      "0.270358049593\n",
      "Loss: \n",
      "0.270363051721\n",
      "Loss: \n",
      "0.270368017509\n",
      "Loss: \n",
      "0.270372958307\n",
      "Loss: \n",
      "0.270377885761\n",
      "Loss: \n",
      "0.270382811942\n",
      "Loss: \n",
      "0.270387749497\n",
      "Loss: \n",
      "0.27039271183\n",
      "Loss: \n",
      "0.270397713301\n",
      "Loss: \n",
      "0.270402769472\n",
      "Loss: \n",
      "0.270407897404\n",
      "Loss: \n",
      "0.270413116016\n",
      "Loss: \n",
      "0.27041844654\n",
      "Loss: \n",
      "0.270423913091\n",
      "Loss: \n",
      "0.270429543403\n",
      "Loss: \n",
      "0.270435369784\n",
      "Loss: \n",
      "0.270441430396\n",
      "Loss: \n",
      "0.270447770983\n",
      "Loss: \n",
      "0.270454447262\n",
      "Loss: \n",
      "0.270461528336\n",
      "Loss: \n",
      "0.270469101673\n",
      "Loss: \n",
      "0.270477280669\n",
      "Loss: \n",
      "0.270486216612\n",
      "Loss: \n",
      "0.270496118695\n",
      "Loss: \n",
      "0.270507289925\n",
      "Loss: \n",
      "0.27052019818\n",
      "Loss: \n",
      "0.270535637907\n",
      "Loss: \n",
      "0.270555185732\n",
      "Loss: \n",
      "0.270583012993\n",
      "Loss: \n",
      "0.270639023464\n",
      "Loss: \n",
      "0.27108703126\n",
      "Loss: \n",
      "0.291301719155\n",
      "Loss: \n",
      "0.291299179489\n",
      "Loss: \n",
      "0.291296686139\n",
      "Loss: \n",
      "0.291294238274\n",
      "Loss: \n",
      "0.291291835062\n",
      "Loss: \n",
      "0.291289475663\n",
      "Loss: \n",
      "0.291287159235\n",
      "Loss: \n",
      "0.291284884934\n",
      "Loss: \n",
      "0.291282651913\n",
      "Loss: \n",
      "0.291280459327\n",
      "Loss: \n",
      "0.291278306331\n",
      "Loss: \n",
      "0.291276192082\n",
      "Loss: \n",
      "0.291274115741\n",
      "Loss: \n",
      "0.29127207647\n",
      "Loss: \n",
      "0.291270073438\n",
      "Loss: \n",
      "0.291268105819\n",
      "Loss: \n",
      "0.291266172794\n",
      "Loss: \n",
      "0.29126427355\n",
      "Loss: \n",
      "0.291262407283\n",
      "Loss: \n",
      "0.291260573198\n",
      "Loss: \n",
      "0.291258770507\n",
      "Loss: \n",
      "0.291256998435\n",
      "Loss: \n",
      "0.291255256215\n",
      "Loss: \n",
      "0.291253543093\n",
      "Loss: \n",
      "0.291251858325\n",
      "Loss: \n",
      "0.291250201179\n",
      "Loss: \n",
      "0.291248570937\n",
      "Loss: \n",
      "0.291246966893\n",
      "Loss: \n",
      "0.291245388352\n",
      "Loss: \n",
      "0.291243834635\n",
      "Loss: \n",
      "0.291242305075\n",
      "Loss: \n",
      "0.29124079902\n",
      "Loss: \n",
      "0.291239315832\n",
      "Loss: \n",
      "0.291237854885\n",
      "Loss: \n",
      "0.29123641557\n",
      "Loss: \n",
      "0.29123499729\n",
      "Loss: \n",
      "0.291233599464\n",
      "Loss: \n",
      "0.291232221525\n",
      "Loss: \n",
      "0.291230862921\n",
      "Loss: \n",
      "0.291229523113\n",
      "Loss: \n",
      "0.291228201578\n",
      "Loss: \n",
      "0.291226897806\n",
      "Loss: \n",
      "0.291225611303\n",
      "Loss: \n",
      "0.291224341587\n",
      "Loss: \n",
      "0.291223088193\n",
      "Loss: \n",
      "0.291221850667\n",
      "Loss: \n",
      "0.291220628571\n",
      "Loss: \n",
      "0.29121942148\n",
      "Loss: \n",
      "0.291218228982\n",
      "Loss: \n",
      "0.291217050679\n",
      "Loss: \n",
      "0.291215886187\n",
      "Loss: \n",
      "0.291214735133\n",
      "Loss: \n",
      "0.291213597158\n",
      "Loss: \n",
      "0.291212471917\n",
      "Loss: \n",
      "0.291211359075\n",
      "Loss: \n",
      "0.291210258311\n",
      "Loss: \n",
      "0.291209169315\n",
      "Loss: \n",
      "0.291208091788\n",
      "Loss: \n",
      "0.291207025445\n",
      "Loss: \n",
      "0.29120597001\n",
      "Loss: \n",
      "0.291204925219\n",
      "Loss: \n",
      "0.29120389082\n",
      "Loss: \n",
      "0.291202866569\n",
      "Loss: \n",
      "0.291201852234\n",
      "Loss: \n",
      "0.291200847593\n",
      "Loss: \n",
      "0.291199852434\n",
      "Loss: \n",
      "0.291198866555\n",
      "Loss: \n",
      "0.291197889761\n",
      "Loss: \n",
      "0.291196921869\n",
      "Loss: \n",
      "0.291195962705\n",
      "Loss: \n",
      "0.2911950121\n",
      "Loss: \n",
      "0.291194069898\n",
      "Loss: \n",
      "0.291193135949\n",
      "Loss: \n",
      "0.29119221011\n",
      "Loss: \n",
      "0.291191292249\n",
      "Loss: \n",
      "0.291190382237\n",
      "Loss: \n",
      "0.291189479957\n",
      "Loss: \n",
      "0.291188585296\n",
      "Loss: \n",
      "0.291187698148\n",
      "Loss: \n",
      "0.291186818416\n",
      "Loss: \n",
      "0.291185946006\n",
      "Loss: \n",
      "0.291185080833\n",
      "Loss: \n",
      "0.291184222817\n",
      "Loss: \n",
      "0.291183371884\n",
      "Loss: \n",
      "0.291182527964\n",
      "Loss: \n",
      "0.291181690995\n",
      "Loss: \n",
      "0.291180860918\n",
      "Loss: \n",
      "0.29118003768\n",
      "Loss: \n",
      "0.291179221234\n",
      "Loss: \n",
      "0.291178411535\n",
      "Loss: \n",
      "0.291177608543\n",
      "Loss: \n",
      "0.291176812225\n",
      "Loss: \n",
      "0.291176022548\n",
      "Loss: \n",
      "0.291175239486\n",
      "Loss: \n",
      "0.291174463015\n",
      "Loss: \n",
      "0.291173693115\n",
      "Loss: \n",
      "0.291172929769\n",
      "Loss: \n",
      "0.291172172965\n",
      "Loss: \n",
      "0.291171422691\n",
      "Loss: \n",
      "0.291170678941\n",
      "Loss: \n",
      "0.291169941709\n",
      "Loss: \n",
      "0.291169210993\n",
      "Loss: \n",
      "0.291168486794\n",
      "Loss: \n",
      "0.291167769114\n",
      "Loss: \n",
      "0.291167057957\n",
      "Loss: \n",
      "0.291166353331\n",
      "Loss: \n",
      "0.291165655243\n",
      "Loss: \n",
      "0.291164963704\n",
      "Loss: \n",
      "0.291164278726\n",
      "Loss: \n",
      "0.291163600322\n",
      "Loss: \n",
      "0.291162928507\n",
      "Loss: \n",
      "0.291162263296\n",
      "Loss: \n",
      "0.291161604706\n",
      "Loss: \n",
      "0.291160952756\n",
      "Loss: \n",
      "0.291160307464\n",
      "Loss: \n",
      "0.291159668849\n",
      "Loss: \n",
      "0.291159036933\n",
      "Loss: \n",
      "0.291158411736\n",
      "Loss: \n",
      "0.291157793279\n",
      "Loss: \n",
      "0.291157181584\n",
      "Loss: \n",
      "0.291156576673\n",
      "Loss: \n",
      "0.291155978568\n",
      "Loss: \n",
      "0.291155387291\n",
      "Loss: \n",
      "0.291154802866\n",
      "Loss: \n",
      "0.291154225313\n",
      "Loss: \n",
      "0.291153654655\n",
      "Loss: \n",
      "0.291153090915\n",
      "Loss: \n",
      "0.291152534113\n",
      "Loss: \n",
      "0.291151984271\n",
      "Loss: \n",
      "0.29115144141\n",
      "Loss: \n",
      "0.291150905551\n",
      "Loss: \n",
      "0.291150376712\n",
      "Loss: \n",
      "0.291149854913\n",
      "Loss: \n",
      "0.291149340174\n",
      "Loss: \n",
      "0.291148832511\n",
      "Loss: \n",
      "0.291148331941\n",
      "Loss: \n",
      "0.291147838482\n",
      "Loss: \n",
      "0.291147352148\n",
      "Loss: \n",
      "0.291146872954\n",
      "Loss: \n",
      "0.291146400914\n",
      "Loss: \n",
      "0.29114593604\n",
      "Loss: \n",
      "0.291145478343\n",
      "Loss: \n",
      "0.291145027835\n",
      "Loss: \n",
      "0.291144584524\n",
      "Loss: \n",
      "0.291144148419\n",
      "Loss: \n",
      "0.291143719528\n",
      "Loss: \n",
      "0.291143297855\n",
      "Loss: \n",
      "0.291142883407\n",
      "Loss: \n",
      "0.291142476186\n",
      "Loss: \n",
      "0.291142076196\n",
      "Loss: \n",
      "0.291141683437\n",
      "Loss: \n",
      "0.291141297909\n",
      "Loss: \n",
      "0.291140919612\n",
      "Loss: \n",
      "0.291140548542\n",
      "Loss: \n",
      "0.291140184695\n",
      "Loss: \n",
      "0.291139828067\n",
      "Loss: \n",
      "0.29113947865\n",
      "Loss: \n",
      "0.291139136438\n",
      "Loss: \n",
      "0.291138801421\n",
      "Loss: \n",
      "0.291138473589\n",
      "Loss: \n",
      "0.29113815293\n",
      "Loss: \n",
      "0.291137839431\n",
      "Loss: \n",
      "0.291137533079\n",
      "Loss: \n",
      "0.291137233856\n",
      "Loss: \n",
      "0.291136941748\n",
      "Loss: \n",
      "0.291136656736\n",
      "Loss: \n",
      "0.291136378799\n",
      "Loss: \n",
      "0.291136107919\n",
      "Loss: \n",
      "0.291135844073\n",
      "Loss: \n",
      "0.291135587239\n",
      "Loss: \n",
      "0.291135337391\n",
      "Loss: \n",
      "0.291135094505\n",
      "Loss: \n",
      "0.291134858554\n",
      "Loss: \n",
      "0.29113462951\n",
      "Loss: \n",
      "0.291134407345\n",
      "Loss: \n",
      "0.291134192028\n",
      "Loss: \n",
      "0.291133983529\n",
      "Loss: \n",
      "0.291133781816\n",
      "Loss: \n",
      "0.291133586854\n",
      "Loss: \n",
      "0.291133398611\n",
      "Loss: \n",
      "0.29113321705\n",
      "Loss: \n",
      "0.291133042136\n",
      "Loss: \n",
      "0.291132873832\n",
      "Loss: \n",
      "0.291132712098\n",
      "Loss: \n",
      "0.291132556897\n",
      "Loss: \n",
      "0.291132408187\n",
      "Loss: \n",
      "0.29113226593\n",
      "Loss: \n",
      "0.291132130081\n",
      "Loss: \n",
      "0.291132000601\n",
      "Loss: \n",
      "0.291131877443\n",
      "Loss: \n",
      "0.291131760566\n",
      "Loss: \n",
      "0.291131649924\n",
      "Loss: \n",
      "0.291131545472\n",
      "Loss: \n",
      "0.291131447163\n",
      "Loss: \n",
      "0.29113135495\n",
      "Loss: \n",
      "0.291131268786\n",
      "Loss: \n",
      "0.291131188624\n",
      "Loss: \n",
      "0.291131114413\n",
      "Loss: \n",
      "0.291131046106\n",
      "Loss: \n",
      "0.291130983651\n",
      "Loss: \n",
      "0.291130927\n",
      "Loss: \n",
      "0.2911308761\n",
      "Loss: \n",
      "0.291130830902\n",
      "Loss: \n",
      "0.291130791352\n",
      "Loss: \n",
      "0.2911307574\n",
      "Loss: \n",
      "0.291130728992\n",
      "Loss: \n",
      "0.291130706076\n",
      "Loss: \n",
      "0.291130688599\n",
      "Loss: \n",
      "0.291130676506\n",
      "Loss: \n",
      "0.291130669746\n",
      "Loss: \n",
      "0.291130668262\n",
      "Loss: \n",
      "0.291130672002\n",
      "Loss: \n",
      "0.291130680911\n",
      "Loss: \n",
      "0.291130694934\n",
      "Loss: \n",
      "0.291130714016\n",
      "Loss: \n",
      "0.291130738102\n",
      "Loss: \n",
      "0.291130767138\n",
      "Loss: \n",
      "0.291130801067\n",
      "Loss: \n",
      "0.291130839836\n",
      "Loss: \n",
      "0.291130883387\n",
      "Loss: \n",
      "0.291130931667\n",
      "Loss: \n",
      "0.291130984619\n",
      "Loss: \n",
      "0.291131042188\n",
      "Loss: \n",
      "0.291131104319\n",
      "Loss: \n",
      "0.291131170956\n",
      "Loss: \n",
      "0.291131242045\n",
      "Loss: \n",
      "0.291131317528\n",
      "Loss: \n",
      "0.291131397353\n",
      "Loss: \n",
      "0.291131481463\n",
      "Loss: \n",
      "0.291131569803\n",
      "Loss: \n",
      "0.291131662318\n",
      "Loss: \n",
      "0.291131758955\n",
      "Loss: \n",
      "0.291131859657\n",
      "Loss: \n",
      "0.291131964372\n",
      "Loss: \n",
      "0.291132073044\n",
      "Loss: \n",
      "0.29113218562\n",
      "Loss: \n",
      "0.291132302046\n",
      "Loss: \n",
      "0.291132422268\n",
      "Loss: \n",
      "0.291132546233\n",
      "Loss: \n",
      "0.291132673888\n",
      "Loss: \n",
      "0.29113280518\n",
      "Loss: \n",
      "0.291132940057\n",
      "Loss: \n",
      "0.291133078466\n",
      "Loss: \n",
      "0.291133220355\n",
      "Loss: \n",
      "0.291133365673\n",
      "Loss: \n",
      "0.291133514368\n",
      "Loss: \n",
      "0.29113366639\n",
      "Loss: \n",
      "0.291133821687\n",
      "Loss: \n",
      "0.291133980209\n",
      "Loss: \n",
      "0.291134141907\n",
      "Loss: \n",
      "0.29113430673\n",
      "Loss: \n",
      "0.291134474629\n",
      "Loss: \n",
      "0.291134645555\n",
      "Loss: \n",
      "0.29113481946\n",
      "Loss: \n",
      "0.291134996295\n",
      "Loss: \n",
      "0.291135176012\n",
      "Loss: \n",
      "0.291135358565\n",
      "Loss: \n",
      "0.291135543906\n",
      "Loss: \n",
      "0.291135731988\n"
     ]
    }
   ],
   "source": [
    "my_NN = MyNN(data, lr=50)\n",
    "\n",
    "for i in range(500):\n",
    "    print(\"Loss: \\n\" + str(np.mean(np.square(my_NN.Y - my_NN.forward_pass())))) # mean sum squared loss\n",
    "    my_NN.forward_pass()\n",
    "    my_NN.backpropagate()\n",
    "    my_NN.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hack]",
   "language": "python",
   "name": "conda-env-hack-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
